# web_page_crawling

- 웹페이지의 텍스트 데이터를 수집하기 위한 서비스입니다.

<br>

## requirements
- selenium : _pip install selenium_
- pandas : _pip install pandas_
  

- chrome webdriver : https://sites.google.com/a/chromium.org/chromedriver/downloads

1. chrome 웹 브라우저를 실행하고 chrome://version을 주소창에 입력해 버전을 확인한 뒤 자신에게 맞는 버전을 다운받습니다.

2. 다운 받은 chromedriver.exe를 blog_crawling.py파일과 동일한 경로에 삽입합니다. 
<br>

## 사용법
blog_crawling.py 파일을 실행합니다